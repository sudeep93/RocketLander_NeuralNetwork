{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Individual Assignment\n",
    "\n",
    "\n",
    "\n",
    "### Reading Data from csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from math import sqrt\n",
    "from random import randrange\n",
    "import csv\n",
    "\n",
    "xDistanceToTarget=[]\n",
    "yDistanceToTarget=[]\n",
    "velX=[]\n",
    "velY=[]\n",
    "with open('ce889_dataCollection.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, skipinitialspace=False)\n",
    "    for val in reader:\n",
    "        xDistanceToTarget.append(float(val[0]))\n",
    "        yDistanceToTarget.append(float(val[1]))\n",
    "        velX.append(float(val[2]))\n",
    "        velY.append(float(val[3]))\n",
    "        \n",
    "\n",
    "    \n",
    "def func_normalize(input):\n",
    "    max_val=max(input)\n",
    "    min_val=min(input)\n",
    "    output=[]\n",
    "    for inputs in input:\n",
    "        output.append((inputs-min_val)/(max_val-min_val))\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def func_normalize(input):\n",
    "    max_val=max(input)\n",
    "    min_val=min(input)\n",
    "    output=[]\n",
    "    for inputs in input:\n",
    "        output.append((inputs-min_val)/(max_val-min_val))\n",
    "    return output\n",
    "\n",
    "\n",
    "                \n",
    "norm_x=func_normalize(xDistanceToTarget)\n",
    "norm_y=func_normalize(yDistanceToTarget)\n",
    "norm_velx=func_normalize(velX)\n",
    "norm_vely=func_normalize(velY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# inputs=[func_normalize(xDistanceToTarget),func_normalize(yDistanceToTarget)]       \n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "norm_x_fold=cross_validation_split(norm_x,16)\n",
    "norm_y_fold=cross_validation_split(norm_y,16)\n",
    "norm_velx_fold=cross_validation_split(norm_velx,16)\n",
    "norm_vely_fold=cross_validation_split(norm_vely,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nor_x) \n",
    "train_input=[]\n",
    "train_output=[]\n",
    "test_input=[]\n",
    "test_output=[]\n",
    "for i in range(len(norm_x_fold)-5):\n",
    "    for j in range(len(norm_x_fold[1])):\n",
    "        train_input.append([[norm_x_fold[i][j]],[norm_y_fold[i][j]]])\n",
    "        train_output.append([[norm_velx_fold[i][j]],[norm_vely_fold[i][j]]])\n",
    "        \n",
    "for i in range(12,len(norm_x_fold)):\n",
    "    for j in range(len(norm_x_fold[1])):\n",
    "        test_input.append([[norm_x_fold[i][j]],[norm_y_fold[i][j]]])\n",
    "        test_output.append([[norm_velx_fold[i][j]],[norm_vely_fold[i][j]]])\n",
    "        \n",
    "    \n",
    "#     print([nor_y[i]])\n",
    "   \n",
    "\n",
    "# print(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    #applying the sigmoid function\n",
    "    return 1 / (1 + math.exp(-(x)))\n",
    "\n",
    "\n",
    "def derSigmoid(self,y):\n",
    "        #applying the dervative sigmoid function\n",
    "    return y*(1-y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MA(X,Y):\n",
    "    return [[X[i][j] + Y[i][j]  for j in range(len(X[0]))] for i in range(len(X))]\n",
    "\n",
    "def MS(X,Y):\n",
    "    return [[X[i][j] - Y[i][j]  for j in range(len(X[0]))] for i in range(len(X))]\n",
    "\n",
    "def MT(X):\n",
    "    return  [[X[j][i] for j in range(len(X))] for i in range(len(X[0]))]\n",
    "\n",
    "def MM(X,Y):          \n",
    "    return [[sum(a*b for a,b in zip(X_row,Y_col)) for Y_col in zip(*Y)] for X_row in X]\n",
    "\n",
    "def createMatrixRandom(rowCount, colCount):\n",
    "    mat = []\n",
    "    for i in range(rowCount):\n",
    "        rowList = []\n",
    "        for j in range(colCount):\n",
    "            rowList.append(round(random.uniform(0.0,1.0), 10))\n",
    "        mat.append(rowList)\n",
    "    return mat\n",
    "\n",
    "def createMatrixofOne(rowCount, colCount):\n",
    "    mat = []\n",
    "    for i in range(rowCount):\n",
    "        rowList = []\n",
    "        for j in range(colCount):\n",
    "        # you need to increment through dataList here, like this:\n",
    "            rowList.append(1)\n",
    "        mat.append(rowList)\n",
    "    return mat\n",
    "\n",
    "\n",
    "def createMatrixofInputorOutput(datalist):\n",
    "    k=0\n",
    "    for i in range(1):\n",
    "        rowList = []\n",
    "        for j in range(len(datalist)):\n",
    "            rowList.append([datalist[k]])\n",
    "            k=k+1\n",
    "    return rowList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def map_sigmoid(matrix):\n",
    "#     rows = len(matrix)\n",
    "#     cols = len(matrix[0])\n",
    "#     for i in range(rows):\n",
    "#         for j in range(cols):\n",
    "#             matrix[i][j]=1 / (1 + (math.exp(-matrix[i][j])))\n",
    "#     return matrix\n",
    "\n",
    "def map_sigmoid(matrix,lamda):\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if matrix[i][j] < 0.0:\n",
    "                matrix[i][j]= 1 - 1 / (1 + math.exp(lamda*matrix[i][j]))\n",
    "            else:\n",
    "                matrix[i][j]=1 / (1 + (math.exp(lamda*-(matrix[i][j]))))\n",
    "    return matrix\n",
    "\n",
    "def multiply(matrix,n):\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            matrix[i][j]*=n\n",
    "    return matrix\n",
    "\n",
    "def multiply_hm(matrix,n):\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            matrix[i][j]*=n[i][j]\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def addition(matrix,n):\n",
    "#         print(matrix)\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "#         print(rows,cols)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            matrix[i][j]+=n\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def addition_hm(matrix,n):\n",
    "#         print(matrix)\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "#         print(rows,cols)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            matrix[i][j]+=n[i][j]\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def map_derSigmoid(matrix):\n",
    "#         print(matrix)\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "#         print(rows,cols)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            matrix[i][j]=matrix[i][j]*(1.0-matrix[i][j])               \n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "# Calculate root mean squared error\n",
    "def rmse_metric(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = predicted[i] - actual[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    mean_error = sum_error / float(len(actual))\n",
    "    return sqrt(mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(func_normalize(df[01]),func_normalize(df[1]))\n",
    "\n",
    "# a=round(random.uniform(0.0,1.0), 2) \n",
    "# print(a)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,input_nodes, hidden_nodes,output_nodes,learning_rate,lamda):\n",
    "        self.input_nodes      = input_nodes\n",
    "        self.hidden_nodes      = hidden_nodes\n",
    "        self.output_nodes   = output_nodes\n",
    "        self.weight_inh = createMatrixRandom(self.hidden_nodes,self.input_nodes)#[[0.4,1.1],[0.9,0.5]]#createMatrixRandom(self.hidden_nodes,self.input_nodes)\n",
    "        self.weight_hop = createMatrixRandom(self.output_nodes,self.hidden_nodes) #[[0.5,0.85]]#createMatrixRandom(self.output_nodes,self.hidden_nodes) \n",
    "        self.bias_inh=createMatrixRandom(self.hidden_nodes,1)#[[0.1],[0.6]]#createMatrixRandom(self.hidden_nodes,1)\n",
    "        self.bias_hop=createMatrixRandom(self.output_nodes,1)#[[1.6]]#createMatrixRandom(self.output_nodes,1)\n",
    "        self.learning_rate=learning_rate\n",
    "        self.lamda=lamda\n",
    "\n",
    "    \n",
    "    def feedforward(self,inputs):\n",
    "#         input to hidden layer\n",
    "        hid_val=MM(self.weight_inh,inputs)# matrix multi\n",
    "        hid_bias=MA(hid_val,self.bias_inh)#matrix addition\n",
    "#         print(hid_bias)\n",
    "#         sigmoid function\n",
    "        hid_act_func=map_sigmoid(hid_bias,self.lamda)\n",
    "#         print(hid_act_func)\n",
    "#        hidden to output layer\n",
    "        out_val=MM(self.weight_hop,hid_act_func)\n",
    "        out_bias=MA(out_val,self.bias_hop)\n",
    "#         print(out_bias)\n",
    "        output=map_sigmoid(out_bias,self.lamda)\n",
    "#         print(output)\n",
    "        return output\n",
    "    \n",
    "    def train(self,inputs,targets):\n",
    "        \n",
    "#         outputs=self.feedforward(inputs)\n",
    "#         hid_val=MM(self.weight_inh,inputs)# matrix multi\n",
    "#         print(\"1\",self.weight_hop)\n",
    "        hid_val=MM(self.weight_inh,inputs)\n",
    "        hid_bias=MA(hid_val,self.bias_inh)\n",
    "#         print(hid_bias)\n",
    "        #         sigmoid function\n",
    "        hid_act_func=map_sigmoid(hid_bias,self.lamda)\n",
    "#         print(hid_act_func)\n",
    "#         output layer\n",
    "        out_val=MM(self.weight_hop,hid_act_func)\n",
    "        out_bias=MA(out_val,self.bias_hop)\n",
    "        outputs=map_sigmoid(out_bias,self.lamda) \n",
    "\n",
    "        \n",
    "#         feedforward output\n",
    "        \n",
    "#        output error calculation\n",
    "        op_errors=MS(targets,outputs)\n",
    "\n",
    "#   gredient calculation gradient = outputs * (1 - outputs);\n",
    "\n",
    "        gredient=map_derSigmoid(outputs)\n",
    "        gredient=multiply_hm(gredient,op_errors)\n",
    "        gredient=multiply(gredient,self.learning_rate)\n",
    "\n",
    "\n",
    "#         hidden to output delta calculation   \n",
    "        hid_valT=MT(hid_val)\n",
    "        weight_hop_del=MM(gredient,hid_valT)\n",
    "        \n",
    "#        adjust weights hidden to output\n",
    "        self.weight_hop=MA(self.weight_hop,weight_hop_del)\n",
    "        self.bias_hop=MA(self.bias_hop,gredient)\n",
    "        \n",
    "#         hidden layer errors\n",
    "        weight_hopT=MT(self.weight_hop)\n",
    "        hid_errors=MM(weight_hopT,op_errors)\n",
    "        \n",
    "#         calculate hidden gredient\n",
    "        hid_gredient=map_derSigmoid(hid_val)\n",
    "        hid_gredient=multiply_hm(hid_gredient,hid_errors)\n",
    "        hid_gredient=multiply(hid_gredient,self.learning_rate)\n",
    "\n",
    "\n",
    "#       calculate in_hid del  \n",
    "        input_val_T=MT(inputs)\n",
    "        weight_inh_del=MM(hid_gredient,input_val_T)\n",
    "        self.weight_inh=MA(self.weight_inh,weight_inh_del)\n",
    "        self.bias_inh=MA(self.bias_inh,hid_gredient)\n",
    "#         print(\"2\",self.weight_hop)\n",
    "#         print(outputs)\n",
    "        return outputs\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=NeuralNetwork(2,3,2,0.8,0.7)\n",
    "# test.backpropogation(train_input[1],train_output[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=NeuralNetwork(2,3,2,0.87,0.6)\n",
    "# inputs=[[1],[0]]\n",
    "# print(len(train_input)\n",
    "epoch=1000\n",
    "\n",
    "for epoch in range(epoch):\n",
    "#     sum_error1=0\n",
    "#     sum_error2=0\n",
    "#     feedOp=[]\n",
    "\n",
    "#     for j in range(len(train_input)):\n",
    "    for j in range(1000,4500):\n",
    "# print(test.train_nn([[0.9709244176705843], [0.4923847132507726]],[[0.5194963577697465], [0.5115763105657878]]))\n",
    "        test.train(train_input[j],train_output[j])\n",
    "        #print(train_input[j],train_output[j])\n",
    "#         sum_error1 += sum([(train_output[j][0][0]-feedOp[0][0])**2 for i in range(len(train_output))])\n",
    "#         sum_error2 += sum([(train_output[j][1][0]-feedOp[1][0])**2 for i in range(len(train_output))])\n",
    "\n",
    "#         sum_error1 += sum([(train_output[k][0][0]-feedOp[0][0])**2 for k in range(50)])\n",
    "#         sum_error2 += sum([(train_output[k][1][0]-feedOp[1][0])**2 for k in range(50)])\n",
    "#     print(\"sum_error1\",sum_error1/len(train_input),\"sum_error2\",sum_error2/len(train_input))\n",
    "#     print(\"sum_error1\",sum_error1,\"sum_error2\",sum_error2)\n",
    "#     print(\"sum_error1\",sum_error1/50,\"sum_error2\",sum_error2/50,epoch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hop---> [[0.6741035824369104, 0.6741035824443282, 0.847580290039126], [1.2986202331847385, 1.2986202331656334, 0.49759006823469465]] inh---> [[0.9209089943538685, 0.30658052178243655], [0.9209089943568972, 0.30658052177712125], [8.754287643059007e-16, -8.905428541240352e-16]] biasinh---> [[25.598927668876176], [25.918727883805126], [-0.2552408514354835]] biashop---> [[-1.8231713517689787], [-2.8572891347283695]]\n"
     ]
    }
   ],
   "source": [
    "print(\"hop--->\",test.weight_hop,\"inh--->\",test.weight_inh,\"biasinh--->\",test.bias_inh,\"biashop--->\",test.bias_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<ipython-input-136-ea624ab9871e>:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  [[-0.3068791741659098, 0.7077797390372979, -0.37384462293478804], [-0.19995363159092375, 0.7455033736712459, 0.047801931489830585]] [[0.8138835828834101, 0.3534836735898184], [0.16424522842231304, -0.13328490614119512], [0.33181510753417603, 0.927872549360914]] [[0.27493020094660015], [0.08328536021987379], [0.6788359598483047]] [[0.25462607278487426], [-0.5191498922474127]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-ea624ab9871e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.3068791741659098\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7077797390372979\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.37384462293478804\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.19995363159092375\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7455033736712459\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.047801931489830585\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.8138835828834101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3534836735898184\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.16424522842231304\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.13328490614119512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.33181510753417603\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.927872549360914\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.27493020094660015\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.08328536021987379\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.6788359598483047\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.25462607278487426\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5191498922474127\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "[[-0.3068791741659098, 0.7077797390372979, -0.37384462293478804], [-0.19995363159092375, 0.7455033736712459, 0.047801931489830585]] [[0.8138835828834101, 0.3534836735898184], [0.16424522842231304, -0.13328490614119512], [0.33181510753417603, 0.927872549360914]] [[0.27493020094660015], [0.08328536021987379], [0.6788359598483047]] [[0.25462607278487426], [-0.5191498922474127]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------> [[0.5352159137526324], [0.46047144133037543]]\n"
     ]
    }
   ],
   "source": [
    "predict_output=[]\n",
    "for i in range(1):\n",
    "    predict_output.append(test.feedforward(test_input[i]))\n",
    "    \n",
    "    \n",
    "print(\"------------->\",test.feedforward(test_input[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(norm_velx_fold)\n",
    "# print([predict_output[2][0][0],predict_output[2][1][0]])\n",
    "predict_output_list=[]\n",
    "actual_output_list=[]\n",
    "# print(len(norm_velx_fold))\n",
    "for i in range(len(predict_output)):\n",
    "#     print(1)\n",
    "    predict_output_list.append([predict_output[i][0][0],predict_output[i][1][0]])\n",
    "    actual_output_list.append([train_output[i][0][0],train_output[i][1][0]])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16313206355816895\n",
      "0.16313206355816895\n"
     ]
    }
   ],
   "source": [
    "actual=[]\n",
    "predict=[]\n",
    "\n",
    "# Calculate mean absolute error\n",
    "def mae_metric(actual, predicted):\n",
    "\tsum_error = 0.0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tsum_error += abs(predicted[i] - actual[i])\n",
    "\treturn sum_error / float(len(actual))      \n",
    "        \n",
    "for i in range(len(actual_output_list)):\n",
    "#     print(rmse_metric(predict_output_list[i][0],actual_output_list[i][0]))\n",
    "#     print(predict_output_list[i],actual_output_list[i])\n",
    "#     print(predict_output_list[i][0])\n",
    "    predict.append(predict_output_list[i][0])\n",
    "    actual.append(actual_output_list[i][0])\n",
    "    \n",
    "# for i in range(len(actual_output_list)):\n",
    "print(rmse_metric(actual,predict))\n",
    "print(mae_metric(actual,predict))\n",
    "# print(rmse_metric(predict_output_list,actual_output_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1349492747870393"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1349492747870393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0252924704108108, 0.956950127009105]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    y=[[0.5274250479182677], [0.4662634301511498]]\n",
    "   \n",
    "    def deNormaliseDataSet(normaliseData):\n",
    "        normVal1 = normaliseData[0][0] - (-7.927907828)/(7.995825017-(-7.927907828))\n",
    "        normVal2 = normaliseData[1][0] - (-5.734376934)/(5.95205551-(-5.734376934))\n",
    "        deNormalisedData=[normVal1,normVal2]\n",
    "        return deNormalisedData\n",
    "    deNormaliseDataSet(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
